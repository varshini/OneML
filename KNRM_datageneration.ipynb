{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "qrels = open('C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\qrels.dev.tsv')\n",
    "qrels_reader = csv.reader(qrels, delimiter = '\\t')\n",
    "qrels_nr = open('C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\qrels_nr.dev.tsv')\n",
    "qrels_nr_reader = csv.reader(qrels_nr, delimiter = '\\t')\n",
    "\n",
    "rel_query_doc = defaultdict(list)\n",
    "nr_query_doc = defaultdict(list)\n",
    "\n",
    "for row in qrels_reader:\n",
    "    query_id = int(row[0])\n",
    "    doc_id = int(row[2])\n",
    "    rel_query_doc[query_id].append(doc_id)\n",
    "    \n",
    "\n",
    "for row in qrels_nr_reader:\n",
    "    query_id = int(row[0])\n",
    "    doc_id = int(row[2])\n",
    "    nr_query_doc[query_id].append(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110808\n"
     ]
    }
   ],
   "source": [
    "#create pairs\n",
    "import random\n",
    "\n",
    "query_pos_neg = []\n",
    "for query in rel_query_doc:\n",
    "    \n",
    "    for pos_doc in rel_query_doc[query]:\n",
    "        for neg_doc in nr_query_doc[query]:\n",
    "            query_pos_neg.append((query,pos_doc,neg_doc))\n",
    "            \n",
    "\n",
    "random.shuffle(query_pos_neg)\n",
    "print (len(query_pos_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get term ids\n",
    "del rel_query_doc\n",
    "del nr_query_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading collections file!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "collections = open(\"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\collection_cleaned_nostemming_termids.tsv\", \"r\")\n",
    "collections_reader = csv.reader(collections, delimiter = '\\t')\n",
    "\n",
    "docid_terms = defaultdict(str)\n",
    "\n",
    "count = 0\n",
    "print(\"Reading collections file!\")\n",
    "for row in collections_reader:\n",
    "    \n",
    "    count += 1\n",
    "    try:\n",
    "        docid = int(row[0])\n",
    "        terms = row[1].split(\",\")\n",
    "        int_terms = [int(i) for i in terms]\n",
    "        str_terms = []\n",
    "        for i in int_terms:\n",
    "            if i == -1:\n",
    "                str_terms.append(str(-1))\n",
    "            else:\n",
    "                str_terms.append(str(i+1))\n",
    "        inc_terms = \",\".join(str_terms)\n",
    "        docid_terms[docid] = inc_terms\n",
    "    except:\n",
    "        print (count)\n",
    "        import pdb;pdb.set_trace()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  open(\"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\queries_termids.dev.tsv\", \"r\")\n",
    "queries_reader = csv.reader(query, delimiter = '\\t')\n",
    "\n",
    "queryid_terms = defaultdict(str)\n",
    "\n",
    "for row in queries_reader:\n",
    "    \n",
    "    qid = int(row[0])\n",
    "    terms = row[1].split(\",\")\n",
    "    int_terms = [int(i) for i in terms]\n",
    "    str_terms = []\n",
    "    for i in int_terms:\n",
    "        if i == -1:\n",
    "            str_terms.append(str(-1))\n",
    "        else:\n",
    "            str_terms.append(str(i+1))\n",
    "    inc_terms = \",\".join(str_terms)\n",
    "    queryid_terms[qid] = inc_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdata = open(\"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\KNRM\\\\pairwise.dev.tsv\",'w')\n",
    "\n",
    "for query,pos,neg in query_pos_neg:\n",
    "    query_terms = queryid_terms[query]\n",
    "    pos_doc_terms = docid_terms[pos]\n",
    "    neg_doc_terms = docid_terms[neg]\n",
    "    trainingdata.write(query_terms + \"\\t\" + pos_doc_terms + \"\\t\" + neg_doc_terms + \"\\t1\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "query =  open(\"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\queries_termids.eval.tsv\", \"r\")\n",
    "queries_reader = csv.reader(query, delimiter = '\\t')\n",
    "\n",
    "top1000 =  open(\"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\top1000.eval.tsv\", \"r\", encoding=\"UTF8\")\n",
    "top1000_reader = csv.reader(top1000, delimiter = '\\t')\n",
    "\n",
    "top1000_terms = open(\"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\KNRM\\\\pointwise.eval.tsv\", \"w\")\n",
    "queryid_terms = defaultdict(str)\n",
    "for row in queries_reader:\n",
    "    qid = int(row[0])\n",
    "    queryid_terms[qid] = row[1]\n",
    "\n",
    "print(\"Creating dataset!\")\n",
    "for row in top1000_reader:\n",
    "    qid = int(row[0])\n",
    "    terms = queryid_terms[qid].split(\",\")\n",
    "    try:\n",
    "        int_terms = [int(i) for i in terms]\n",
    "    except:\n",
    "        import pdb;pdb.set_trace()\n",
    "    str_terms = []\n",
    "    for i in int_terms:\n",
    "        if i == -1:\n",
    "            str_terms.append(str(-1))\n",
    "        else:\n",
    "            str_terms.append(str(i+1))\n",
    "    inc_terms = \",\".join(str_terms)\n",
    "    query_terms = inc_terms\n",
    "    \n",
    "    doc_id = int(row[1])\n",
    "    doc_terms = docid_terms[doc_id]\n",
    "    top1000_terms.write(query_terms + \"\\t\" + doc_terms + \"\\n\")\n",
    "top1000_terms.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1,13099,1155,3946,461,126384,76,2335,927,461,231,2645,1403,7908,-1,3510,459,2300,-1,161,158,-1,42,6066,-1,21956,816,-1,3816,-1,-1,5324,200,-1,5320,5324\n"
     ]
    }
   ],
   "source": [
    "d = \"-1,13100,1156,3947,462,126385,77,2336,928,462,232,2646,1404,7909,-1,3511,460,2301,-1,162,159,-1,43,6067,-1,21957,817,-1,3817,-1,-1,5325,201,-1,5321,5325\"\n",
    "d = d.split(\",\")\n",
    "c = []\n",
    "for i in d:\n",
    "    if i == \"-1\":\n",
    "        c.append(\"-1\")\n",
    "    else:\n",
    "        c.append(str(int(i)-1))\n",
    "print(\",\".join(c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
