{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4c9ccb5c285c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mfw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\t\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from importlib import reload\n",
    "import logging\n",
    "import csv\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "import gensim\n",
    "import pickle\n",
    "from gensim.summarization.bm25 import BM25\n",
    "\n",
    "\n",
    "porterStemmer = PorterStemmer()\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def removeNonAscii(s):\n",
    "    return \"\".join(filter(lambda x:ord(x) < 128, s))\n",
    "\n",
    "\n",
    "def preprocess(passage):\n",
    "    clean_passage = passage.lower()\n",
    "    clean_passage = removeNonAscii(clean_passage)\n",
    "    clean_passage = clean_passage.translate(str.maketrans('', '', string.punctuation)) \n",
    "    \n",
    "    clean_passage_list = clean_passage.split()\n",
    "    clean_passage_list_stem = []\n",
    "    for word in clean_passage_list:\n",
    "        if word not in gensim.parsing.preprocessing.STOPWORDS:\n",
    "            clean_passage_list_stem.append(porterStemmer.stem(word))\n",
    "    return clean_passage_list_stem\n",
    "\n",
    "    \n",
    "inputFile = \"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\collection.tsv\"\n",
    "corpus = []\n",
    "count = 0\n",
    "with open(inputFile, 'r', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        assert count == int(row[0])\n",
    "        passage = row[1]\n",
    "        corpus.append(preprocess(passage))\n",
    "        count += 1\n",
    "        if count % 1000000 == 0:\n",
    "            print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\collection_cleaned.tsv\", \"w\") as fw:\n",
    "    count = 0\n",
    "    for line in corpus:\n",
    "        fw.write(str(count) + \"\\t\" + \" \".join(line) + \"\\n\")\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25(corpus)\n",
    "bm25.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\model\\\\bm25.pkl\", 'wb') as fw:\n",
    "    pickle.dump(bm25, fw, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.422092756837039"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(\"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\model\\\\bm25.pkl\", 'rb') as fr:\n",
    "#     bm25 = pickle.load(fr)\n",
    "\n",
    "average_idf = sum(map(lambda k: float(bm25.idf[k]), bm25.idf.keys())) / len(bm25.idf.keys()) \n",
    "query = \"manhattan project\"\n",
    "query_list = preprocess(query)\n",
    "bm25.get_score(query_list, 7, average_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "queryFile = \"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\top1000.eval.tsv\"\n",
    "query_id_text = defaultdict(str)\n",
    "query_doc_ids = defaultdict(list)\n",
    "query_id_scores = defaultdict(list)\n",
    "with open(queryFile, 'r', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        query_id_text[row[0]] = preprocess(row[2])\n",
    "        query_doc_ids[row[0]].append(row[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_id, text in query_id_text.items():\n",
    "    for doc_id in query_doc_ids[query_id]:\n",
    "        score = bm25.get_score(text, int(doc_id), average_idf)\n",
    "        query_id_scores[query_id].append((doc_id, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFile = \"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\output\\\\bm25.eval.tsv\"\n",
    "fw = open(outputFile, \"w\")\n",
    "for query_id in query_id_scores.keys():\n",
    "    query_id_scores[query_id] = sorted(query_id_scores[query_id], key=lambda x:x[1], reverse=True)[:10]\n",
    "    for doc_id_score, rank in zip(query_id_scores[query_id], range(10)):\n",
    "        fw.write(str(query_id) + \"\\t\" + str(doc_id_score[0]) + \"\\t\" + str(rank+1) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6837"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_id_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "inputFile = \"C:\\\\Users\\\\mapyredd\\\\Documents\\\\marco\\\\data\\\\collection.tsv\"\n",
    "with open(inputFile, 'r', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        assert count == int(row[0])\n",
    "        count += 1\n",
    "        if count % 1000000 == 0:\n",
    "            print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
